---
title: "An example for the use of DARth ABC functions for the analysis of abundance of radiocarbon dates"
author: "Miguel de Navascués"
date: "`r Sys.Date()`"
output: html_document
---

```{r knitr_setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

Note: this vignette assumes that the user has read the article Navascués *et al.* (2024, [doi:10.5281/zenodo.13683747](https://doi.org/10.5281/zenodo.13683747)) first.

## Setting up the analysis

Functions for the analysis of the abundance of radiocarbon dates are loaded from file `DARthABC.R`. This file contains all the functions necessary for the analysis presented in this vignette and in the analyses presented in Navascués *et al.* (2024, [doi:10.5281/zenodo.13683747](https://doi.org/10.5281/zenodo.13683747)). It also loads `rcarbon` package, which contains the data set used in this example `euroevol`. This data set contains radiocarbon dates from Neolithic Europe from the EUROEVOL project database (Manning *et al.* [2016, doi:10.5334/joad.40](https://doi.org/10.5334/joad.40)). We will analyse the abundance of radiocarbon ages during the period 8000 cal BP and 4000 cal BP in the whole Europe. Note that, in practice, this time interval is chosen to be larger than the period of interest because the estimates around the edges of the interval have higher error due to the discrepancy between conventional radiocarbon ages (CRA) and calibrated ages.

```{r setup, message = FALSE}
source("scripts/DARthABC.R")
data(euroevol)
target_data = list(CRA = euroevol$C14Age, error = euroevol$C14SD)
time_range = c(8000, 4000)
```

## Characterizing the data set with summary statistics

The statistical analysis will be based on an Approximate Bayesian Computation (ABC) approach. ABC is a simulation based inference approach that compares the real data with simulated data and then 'compares' simulated and real data to determine which simulations better explain the observation. This 'comparison' requires reduce the dimensionality of the data into summary statistics that are informative about the abundance radiocarbon ages. This is done with function `get_sumstats()` from `DARthABC.R` file. These summary statistics are calculated in the time interval defined above, that is, CRA older or younger that the time interval define above, are discarded. Note that in this function the times in `time_range` are taken as if they were CRA.

```{r sumstats}
target_sumstat = get_sumstats(target_data, time_range)
```

Some of the summary statistics calculated are the total number of samples $n=$ `r target_sumstat$n` (`target_sumstat$n`), the number of samples in the CRA interval $(8000, 7950)$ $H_{(8000, 7950)}=$ `r target_sumstat$h7975_w50` (`target_sumstat$h7975_w50`) and the difference in number of samples between consecutive intervals   $\Delta H_{(7950,7900)}=H_{(7950, 7900)}-H_{(8000, 7950)}=$  `r target_sumstat$dh7925_w50` (`target_sumstat$dh7925_w50`). More details about the summary statistics can be read in the article (Navascués *et al.* 2024, [doi:10.5281/zenodo.13683747](https://doi.org/10.5281/zenodo.13683747)). A representation of statistic $H$ for all CRA intervals of size 50 years is represent in the following plot.

```{r plot_sumstats, echo = FALSE}
barplot(as.vector(t(target_sumstat[2:82])), names.arg=seq(8000, 4000, -50), ylab=expression(italic(H)), xlab="CRA")
box()
```

## Generate reference table for exponential model for ABC analysis

In ABC, the reference table consists on a data frame that contains for each simulation (in rows) the parameter values used in the simulation and the summary statistics calculated from the data generated by the simulation. The following steps are going to generate such a table using a model of exponential change for $\lambda$. The parameters of the model are the initial value of $\lambda_0$ at time $t_0$ and and the rate $r$ of exponential change. The reference table will have two columns with the values of $\lambda_0$ and $r$. The additional columns will be the same summary statistics calculated for real data ($n$, $H$, $\Delta H$).

The reference table in this example is build in a `for` loop with six steps:

1. Sample of parameter values from the prior probability distribution. In this case $\lambda_0$ is taken from a log-uniform distribution between $0.001$ and $1$. These limits correspond to an expected number of dated archaeological record of 1 sample every 1000 years to 1 sample every year. The rate parameter $r$ is taken from a uniform distribution between $-0.001$ and $0.001$.

2. Calculate $\lambda$ for each year in the studied period (variable `lambda_t`) using the exponential model and the values of  $\lambda_0$ and $r$ obtained in th previous step.

3. Simulate an archaeological sample with the Poisson distribution for each year in the studied period. This yield a vector of dates (`dates`) that correspond to the true age of of each of the individual samples.

4. Simulate the radiocarbon reading for each individual sample, using a calibration curve (in this case the default, IntCal20; but other curves can be specified with `calCurves` parameter). The result is a list with the simulated CRA (`dates_CRA`).

5. Characterize the simulated data with the same summary statistics calculated for the real data.

6. Save paramters and summary statistics in the reference table.

```{r reftable, cache = TRUE}
num_of_sims = 10000
col_names = c("lambda_0", "rate", colnames(target_sumstat))
reftable = data.frame(matrix(NA, nrow = num_of_sims, ncol = length(col_names)))
colnames(reftable) = col_names
for (i in seq_len(num_of_sims)){
  lambda_0 = 10^runif(1, log10(0.001), log10(1))
  rate = runif(1, -0.001, 0.001)
  params = cbind(lambda_0, rate)
  lambda_t = get_exponential_lambda_t(lambda_0, rate, time_range)
  dates = sim_dates_lambda(lambda_t, time_range)
  dates_CRA = sim_CRA(dates, errors = target_data$error)
  sumstats = get_sumstats(dates_CRA, time_range)
  reftable[i,] = cbind(params, sumstats)
}
```

## Approximate Bayesian Computation

Several algorithms exist to perform simulation based inference once a reference table has been produce. Classical rejection and regression algorithms are available in R package `abc`. In this example Approximate Bayesian Computation *via* Ramdom Forests (ABCRF) will be used as implemented in package `abcrf`. ABCRF works by estimating each parameter separately (thus, estimating the marginal posterior probability distribution). For each parameter, the reference table is used to grow a random forest regression between the summary statistics and the parameter (`parameter~summary_statistics`), then the observed summary statistics are used to predict the value of the parameters. The weights obtained for each parameter value in the reference table allow to estimate the whole posterior distribution (allowing to provide credibility intervals).

```{r abcrf, message = FALSE}
require(abcrf)
rate = reftable$rate
lambda_0 = reftable$lambda_0
sumstats = reftable[names(target_sumstat)]

RFmodel_rate = regAbcrf(rate~., data.frame(rate,sumstats), ntree = 1000, paral = TRUE)
rate_posterior = predict(RFmodel_rate, obs = target_sumstat, training = data.frame(rate, sumstats), paral = TRUE, rf.weights = TRUE)

RFmodel_lambda_0 = regAbcrf(lambda_0~., data.frame(lambda_0,sumstats), ntree = 1000, paral = TRUE)
lambda_0_posterior = predict(RFmodel_lambda_0, obs = target_sumstat, training = data.frame(lambda_0, sumstats), paral = TRUE, rf.weights = TRUE)
```

Point estimate of exponential change rate, $r$, is `r rate_posterior$med` with 95% credibility interval (`r rate_posterior$quantile[1]` , `r rate_posterior$quantile[2]`).

Point estimate of $\lambda_0$, is `r lambda_0_posterior$med` with 95% credibility interval (`r lambda_0_posterior$quantile[1]` , `r lambda_0_posterior$quantile[2]`).

The full posterior probability distribution can be plotted to examine the uncertainty of the estimation.


```{r plot_posterior, message = FALSE}
breaks = seq(-0.001,0.001,0.00004)
hist(rate, breaks = breaks, main = "", xlab = expression("exponential rate change, "*italic(r)), ylim = c(0,4000), col = adjustcolor( "gray", alpha.f = 0.6), freq = FALSE)
wtd.hist(rate, breaks = breaks, col = rgb(44, 110.4, 148.3, 100, maxColorValue = 255), weight = rate_posterior$weights, add = TRUE, freq = FALSE)
legend("topleft",c("prior","posterior"), fill=c(adjustcolor( "gray", alpha.f = 0.6),rgb(44, 110.4, 148.3, 100, maxColorValue = 255)))
box()

breaks = seq(-3,0,0.05)
hist(log10(lambda_0), breaks = breaks, main = "", xlab = expression(log[10](italic(lambda))), ylim = c(0,5), col = adjustcolor( "gray", alpha.f = 0.6), freq = FALSE)
wtd.hist(log10(lambda_0), breaks = breaks, col = rgb(44, 110.4, 148.3, 100, maxColorValue = 255), weight = lambda_0_posterior$weights, add = TRUE, freq = FALSE)
legend("topleft",c("prior","posterior"), fill=c(adjustcolor( "gray", alpha.f = 0.6),rgb(44, 110.4, 148.3, 100, maxColorValue = 255)))
box()
```

